<!DOCTYPE html>
<html>
<head>

  <meta charset="utf-8">
  <meta name="description"
        content="EvalMuse-40K: A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation">
  <meta name="keywords" content="Evaluation, Benchmark, Prompts, Dataset, Image Alignment Evaluation, Text-to-Image, AIGC, Image Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EvalMuse-40K: A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation</title>

<!--   Global site tag (gtag.js) - Google Analytics-->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y5ZVQZ7NHC"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-Y5ZVQZ7NHC');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="https://cdn.datatables.net/1.13.6/css/jquery.dataTables.min.css">

  <link rel="stylesheet" href="./assets/css/bulma.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./assets/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./assets/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./assets/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./assets/js/fontawesome.all.min.js"></script>
  <script src="./assets/js/bulma-carousel.min.js"></script>
  <script src="./assets/js/bulma-slider.min.js"></script>
  <script src="./assets/js/index.js"></script>
  
</head>
<body>

<!-- title -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title"><span style="color:#B9770E; font-weight: bold; font-style: italic">EvalMuse-40K</span> : A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"></span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            
            <span class="link-block">
              <a href="https://arxiv.org/abs/2412.18150" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>Paper (EvalMuse-40K)</span>
              </a>
            </span>
            <!-- Video Link. -->
            <span class="link-block">
              <a href="https://www.youtube.com/embed/vGpMfIC1wNA?si=InvXBj3rgqjh8hMY" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>
            <!-- Code Link. -->
            <span class="link-block">
              <a href="https://github.com/DYEvaLab/EvalMuse" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>GitHub</span>
              </a>
            </span>
            <!-- Huggingface Demo Link. -->
            <span class="link-block">
              <a href="https://huggingface.co/datasets/DY-Evalab/EvalMuse" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <img src="assets/images/logo/hf-logo.svg" style="display:block;width:330px;height:240px" />
                </span>
                <span>Datasets</span>
              </a>
            </span>
			<span class="link-block">
				<a href="https://shh-han.github.io/EvalMuse-Leaderboard/" target="_blank"
				  class="external-link button is-normal is-rounded is-dark">
				  <span class="icon">
					<img src="assets/images/logo/leaderboard.svg" style="display:white;width:330px;height:240px" />
				  </span>
				  <span>LeaderBoard</span>
				</a>
			  </span>
            <!-- Dataset Link. -->
            <!-- <span class="link-block">
              <a href="" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="far fa-images"></i>
                </span>
                <span>Dataset</span>
              </a> -->
          </div>

        </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop" style="width: 50%; max-width: none;">
      <div class="hero-body">
            <img src="assets/images/framework.png" style="width:100%; margin-bottom:10px" alt="Teaser."/>
      <p style="margin-top: 0;">
        <b>Overview of EvalMuse-40K</b>, consisting of (a) <b>data collection</b>, (b) <b>data annotation</b>, and (c) <b>evaluation methods</b>. <b>(a)</b> We collected 2K real prompts and 2K synthetic prompts, using the MILP sampling strategy to ensure category balance and diversity. Prompts are further divided into elements, and corresponding questions are generated. We also use various T2I models to generate images. <b>(b)</b> During data annotation, we labeled the fine-grained alignment levels of image-text pairs, structural problems about the generated images, and some extra information. For annotated data with large differences in overall alignment scores, we performed re-annotation to ensure the reliability of the benchmark. <b>(c)</b> We proposed two effective image-text alignment evaluation methods: one is <b>FGA-BLIP2</b>, using a fine-tuned vision-language model for direct fine-grained scoring of image-text pairs, and another is <b>PN-VQA</b>, adopting positive-negative VQA manner for zero-shot evaluation.
      </p>
    </div>
  </div>
</section>


<!-- Paper video. -->
<section class="hero is-light">
  <div class="columns is-centered has-text-centered"  style="margin-top: 0px; margin-bottom: 10px;">
    <div class="column is-three-fifths">
      <h2 class="title is-3">Video</h2>
      <div class="publication-video">
        <iframe width="560" height="315" src="https://www.youtube.com/embed/vGpMfIC1wNA?si=InvXBj3rgqjh8hMY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </div>

    </div>
  </div>
</section>
<!-- / Paper video.   -->

<!-- Abstract. -->
<section>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered" style="margin-top: 10px; margin-bottom: 0px;">
      <div class="column is-four-fifths">
        <h2 class="title is-3 is-centered">Abstract</h2>
        <div class="content has-text-justified">
          <p>
			Recently, Text-to-Image (T2I) generation models have achieved significant advancements. 
			Correspondingly, many automated metrics have emerged to evaluate the image-text alignment capabilities of generative models.
			However, the performance comparison among these automated metrics is limited by existing small datasets. 
			Additionally, these datasets lack the capacity to assess the performance of automated metrics at a fine-grained level.
			In this study, we contribute an <b>EvalMuse-40K</b> benchmark, gathering <b>40K</b> image-text pairs with <b>fine-grained</b> human annotations for image-text alignment-related tasks.
			In the construction process, we employ various strategies such as <b>balanced prompt sampling</b> and <b>data re-annotation</b> to ensure the diversity and reliability of our benchmark.
			This allows us to comprehensively evaluate the effectiveness of image-text alignment metrics for T2I models.
			Meanwhile, we introduce two new methods to evaluate the image-text alignment capabilities of T2I models: <b>FGA-BLIP2</b> which involves end-to-end fine-tuning of a vision-language model to produce fine-grained image-text alignment scores and <b></b> which adopts a novel positive-negative VQA manner in VQA models for zero-shot fine-grained evaluation.
			Both methods achieve impressive performance in image-text alignment evaluations. 
			We also use our methods to rank current AIGC models, in which the results can serve as a reference source for future study and promote the development of T2I generation.
          </p>
        </div>
      </div>
    </div>
</section>
<hr>
<!--/ Abstract. -->

<!-- Data Statistics. -->
<section class="section" style="margin-top:-70px; margin-bottom:-100px;">
	<div class="container is-max-desktop">
	  <div class="hero-body">
		  <div class="section-title">
			<h2 class="title is-3 is-centered">Data Statistics in EvalMuse-40K</h2>
		  </div>
		  <div class="section-title">
			<h2 class="title is-4 is-centered">Word Cloud</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/wordcloud_output.png" style="width:600px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
			<b>We used the word cloud to visualize the distribution of words among the elements of prompts in EvalMuse-40K.</b>
		  </p>

		  <div class="section-title" style="margin-top: 30px;">
			<h2 class="title is-4 is-centered">Real Prompt Sampling</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/prompt_sample.png" style="width:1000px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
			<b>Distribution of data before and after sampling in four dimensions using MILP strategy.</b> 
			We randomly sampled 100K prompts from DiffusionDB and then categorized them in four dimensions.
			It can be observed that through MILP
sampling, the distribution of prompts across various dimensions is more balanced.
		  </p>

		  <div class="section-title" style="margin-top: 30px;">
			<h2 class="title is-4 is-centered">Alignment Score Distribution</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/score_proportion.png" style="width:400px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
			<b>We visualize the distribution of alignment scores in EvalMuse-40K.</b> It can be seen that the alignment scores are widely distributed, providing a rich sample for evaluating the consistency of existing models in metrics of image-text alignment with respect to human preferences.
		  </p>

		  <div class="section-title" style="margin-top: 30px;">
			<h2 class="title is-4 is-centered">Differences in Human Preferences</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/diff.png" style="width:400px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
			<b>We visualize differences in alignment scores across human annotations.</b> We found 75% of alignment scores differ by less than 1, showing high annotation consistency. For larger differences, we re-annotated to reduce bias.
		  </p>

		  <div class="section-title" style="margin-top: 30px;">
			<h2 class="title is-4 is-centered">Fine-Grained Annotation Quantity and Scores</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/element_combined.png" style="width:400px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
			<b>We visualize the number and scores of fine-grained annotations.</b> Most categories have alignment scores around 50%, ensuring balanced positive and negative samples. And we found that AIGC models show weaker consistency in counting, spatial relationships, and activities with prompts.
		  </p>

	  </div>
	</div>
</section>
<hr>
<!-- Data Statistics. -->

<!-- Evaluation Results in EvalMuse-40K. -->
<section class="section" style="margin-top:-70px; margin-bottom:-100px;">
	<div class="container is-max-desktop">
	  <div class="hero-body">
		  <div class="section-title">
			<h2 class="title is-3 is-centered">Evaluation Results in EvalMuse-40K</h2>
		  </div>
		  <div class="section-title">
			<h2 class="title is-4 is-centered">Overall Alignment Evaluation on Multiple Benchmarks</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/radar_fga.png" style="width:600px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
			<!-- We visualize the results of our proposed FGA-BLIP2 and other state-of-the-art methods which only use image-text pair to output overall alignment score on multiple benchmarks. -->
		  </p>

		  <div class="section-title" style="margin-top: 30px;">
			<h2 class="title is-4 is-centered">Overall Alignment Evaluation on Multiple Benchmarks</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/radar_fine.png" style="width:600px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
		  </p>

		  <div class="section-title" style="margin-top: 30px;">
			<h2 class="title is-4 is-centered">Overall Alignment Evaluation on Multiple Benchmarks</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <div class="publication-img">
				<img id="architecture" src="assets/images/radar_t2i.png" style="width:600px; margin-top:10px;"/>
			  </div>
			</div>
		  </div>
		  <p style="margin-top: 0;">
		  </p>

	  </div>
	</div>
</section>
<hr>
<!-- Evaluation Results in EvalMuse-40K. -->

<!-- Data Statistics. -->
<!-- <section class="section" style="margin-top:0px; margin-bottom:0px;">
	<div class="hero-body">
	  <div class="container is-max-desktop">
		<div class="section-title">
		  <h2 class="title is-3">Data Statistics in EvalMuse-40K</h2>
		  <h2></h2>
		</div>
		<div id="results-carousel-face" class="carousel results-carousel">
		  <div class="item item-puppet">
				<div class="carousel-content">
					<div class="image-container">
						<p class="image-caption">
							<br>
						</p>
						  <img src="assets/images/wordcloud_output.png" alt="Flicker and Subject" style="width:70%; height:auto;">
						<p class="image-caption">
							<b>We used the word cloud to visualize the distribution of words among the elements of prompts in EvalMuse-40K</b> 
						</p>
					</div>
				</div>
			  </div>
			<div class="item item-round_bird">
			<div class="carousel-content">
				<div class="image-container">
					<p class="image-caption">
						<br>
					</p>
			  		<img src="assets/images/score_proportion.png" alt="Flicker and Subject" style="width:50%; height:auto;">
					<p class="image-caption">
						<b>We visualize the distribution of alignment scores in EvalMuse-40K.</b> It can be seen that the alignment scores are widely distributed, providing a rich sample for evaluating the consistency of existing models in metrics of image-text alignment with respect to human preferences.
					</p>
				</div>
			</div>
		  </div>
		<div class="item item-puppet">
			<div class="carousel-content">
				<div class="image-container">
					<p class="image-caption">
						<br>
					</p>
			  		<img src="assets/images/diff.png" alt="Flicker and Subject" style="width:50%; height:auto;">
					<p class="image-caption">
						<b>We visualize differences in alignment scores across human annotations.</b> We found 75% of alignment scores differ by less than 1, showing high annotation consistency. For larger differences, we re-annotated to reduce bias.
					</p>
				</div>
			</div>
		  </div>
		<div class="item item-round_bird">
			<div class="carousel-content">
				<div class="image-container">
					<p class="image-caption">
						<br>
					</p>
			  		<img src="assets/images/element_combined.png" alt="Flicker and Subject" style="width:50%; height:auto;">
					<p class="image-caption">
						<b>We visualize the number and scores of fine-grained annotations.</b> Most categories have alignment scores around 50%, ensuring balanced positive and negative samples. And we found that AIGC models show weaker consistency in counting, spatial relationships, and activities with prompts.
					</p>
				</div>
			</div>
		  </div>

		  </div>
		</div>
	  </div>
	</div>
</section> -->
<!-- Data Statistics. -->


<!-- Examples for Alignment Evaluation -->
<section class="section" style="margin-top:-70px; margin-bottom:-70px;">
	<div class="hero-body">
	  <div class="container is-max-desktop">
		<div class="section-title">
			<h2 class="title is-3">Examples for Alignment Evaluation</h2>
		  </div>
		<div class="section-title">
		  <h2 class="title is-4">Overall Alignment Score evaluation</h2>
		</div>
		<!-- Single Line -->
		<div id="results-carousel-face" class="carousel results-carousel">
		  <div class="item item-puppet">
				<div class="carousel-content">
					<div class="image-container">
						  <img src="assets/images/blip2_vis1_1.png" alt="Flicker and Subject" style="width:70%; height:auto;">
					</div>
				</div>
			  </div>
			<div class="item item-round_bird">
			<div class="carousel-content">
				<div class="image-container">
			  		<img src="assets/images/blip2_vis1_2.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				</div>
			</div>
		  </div>
		<div class="item item-puppet">
			<div class="carousel-content">
				<div class="image-container">
			  		<img src="assets/images/blip2_vis1_3.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				</div>
			</div>
		  </div>
		<div class="item item-round_bird">
			<div class="carousel-content">
				<div class="image-container">
			  		<img src="assets/images/blip2_vis1_4.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				</div>
			</div>
		  </div>

		  </div>
		  <div class="section-title">
			<h2 class="title is-4" style="margin-top: 30px;">Fine-Grained Alignment Score Evaluation</h2>
		  </div>
		  <div id="results-carousel-face" class="carousel results-carousel">
			<div class="item item-puppet">
				  <div class="carousel-content">
					  <div class="image-container">
							<img src="assets/images/VQA1_1.png" alt="Flicker and Subject" style="width:70%; height:auto;">
					  </div>
				  </div>
				</div>
			  <div class="item item-round_bird">
			  <div class="carousel-content">
				  <div class="image-container">
						<img src="assets/images/VQA1_2.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				  </div>
			  </div>
			</div>
		  <div class="item item-puppet">
			  <div class="carousel-content">
				  <div class="image-container">
						<img src="assets/images/VQA1_3.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				  </div>
			  </div>
			</div>
		  <div class="item item-round_bird">
			  <div class="carousel-content">
				  <div class="image-container">
						<img src="assets/images/VQA1_4.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				  </div>
			  </div>
			</div>
  
			</div>
		</div>
	  </div>
	</div>
	<br>
</section>
<hr>
<!-- Examples for Alignment Evaluation -->

<!-- Submission Guideline-->
<section class="section" style="margin-top:-70px; margin-bottom:0px;" id="guideline">
	<div class="container is-max-desktop">
		<div class="hero-body">
			<div class="section-title">
			<h2 class="title is-3">Submission Guideline</h2>
			</div>
			<p>Our EvalMuse-40K can be used to evaluate the following three tasks, including:</p>
			<ul style="list-style-type: disc; margin-left: 20px;">
				<li>Evaluating the correlation of the <strong>overall image-text alignment scores</strong> with human preferences.</li>
				<li>Evaluating the correlation of the <strong>fine-grained image-text alignment scores</strong> with human preferences.</li>
				<li>Evaluating the <strong>performance of the T2I model</strong> on the image-text alignment task.</li>
			</ul>
			<p>Detailed information can be found in the <a href = "https://shh-han.github.io/EvalMuse-Leaderboard/">leaderboard</a>.</p>
			<br>
			<p>For evaluating model correlation with human preference, you can download our dataset from <a href="https://huggingface.co/datasets/DY-Evalab/EvalMuse" target="_blank">Huggingface</a>.You can train with our training set (with human-annotated scores) and output the results of the model on the test set. Since the test set does not  include human-annotated scores (they will be available later), you can email <a href="mailto:fanhaotian@bytedance.com">fanhaotian@bytedance.com</a> to submit your result in JSON format and get the correlation with human preferences.</p>
			<br>
			<p>For evaluating the image-text alignment performance of the T2I model, we recommend using <strong>FGA-BLIP2</strong>, which achieves good performance in both overall alignment and fine-grained alignment.</p>
		</div>
	</div>
</section>
<!-- Submission Guideline. -->

<!-- Fine-grained alignment score evaluation. -->
<!-- <section class="hero is-light" style="margin-top:-100px; margin-bottom:-50px;">
	<div class="hero-body">
	  <div class="container is-max-desktop">
		<div class="section-title">
		  <h2 class="title is-3">Fine-Grained Alignment Score Evaluation</h2>
		</div>
		<div id="results-carousel-face" class="carousel results-carousel">
		  <div class="item item-puppet">
				<div class="carousel-content">
					<div class="image-container">
						<p class="image-caption">
							<br>
						</p>
						  <img src="assets/images/VQA1_1.png" alt="Flicker and Subject" style="width:70%; height:auto;">
					</div>
				</div>
			  </div>
			<div class="item item-round_bird">
			<div class="carousel-content">
				<div class="image-container">
					<p class="image-caption">
						<br>
					</p>
			  		<img src="assets/images/VQA1_2.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				</div>
			</div>
		  </div>
		<div class="item item-puppet">
			<div class="carousel-content">
				<div class="image-container">
					<p class="image-caption">
						<br>
					</p>
			  		<img src="assets/images/VQA1_3.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				</div>
			</div>
		  </div>
		<div class="item item-round_bird">
			<div class="carousel-content">
				<div class="image-container">
					<p class="image-caption">
						<br>
					</p>
			  		<img src="assets/images/VQA1_4.png" alt="Flicker and Subject" style="width:70%; height:auto;">
				</div>
			</div>
		  </div>

		  </div>
		</div>
	  </div>
	</div>
</section> -->
<!-- Fine-grained alignment score evaluation. -->

<!-- Leaderboard. -->
<!-- <section class="hero is-light" style="margin-top:-100px; margin-bottom:-50px;">
	<div class="container is-max-desktop">
	  <div class="hero-body">
		  <div class="section-title">
			<h2 class="title is-3 is-centered">Leaderboard</h2>
		  </div>
		  <div class="columns is-centered has-text-centered">
			<div class="column">
			  <iframe
			  src="http://localhost:8080/"
			  frameborder="0"
			  width="1400"
			  height="700"
			 ></iframe>
			</div>
		  </div>
	  </div>
	</div>
  </section> -->
<!-- / Leaderboard. -->

<!-- footer -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!-- footer -->

</body>
</html>


